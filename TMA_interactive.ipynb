{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TMA cutting\n",
    "In the XML file provide by miniMIBI, xy of points will be translated into '<RowNumber0 XAttrib=\"-86900\" YAttrib=\"180340\" /\\>', by directly x 10000 to make sure all number are integer.\n",
    "\n",
    "\n",
    "Two slides region,  \n",
    "upper one:\n",
    "(827, 609), (827, 1144), (2200, 609), (2200, 1144)  \n",
    "or  \n",
    "(827, 609), (220, 1144)\n",
    "\n",
    "lower one:\n",
    "(827, 1447), (827, 1989), (2200, 1447), (2200, 1989)  \n",
    "or  \n",
    "(827, 1447), (2200, 1989)\n",
    "\n",
    "#upper = img[609:1144, 827:2200]\n",
    "#lower = img[1447:1989, 827:2200]\n",
    "\n",
    "\n",
    "## Selection between different kinds of sample \n",
    "Different kinds of samples involve change of the parameters during the experiments.  \n",
    "  \n",
    "large TMA: 20 < w, h < 60, 10 < radius < 30  \n",
    "small TMA: 10 < w, h < 25, 5 < radius < 15  \n",
    "lymph nodes:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample position and scale\n",
    "Image size 2600 x 2600 pixel, the real size of hold on MIBIscope is:  \n",
    "x: [-51.816 (left), 51.689(right)]  unit: mm,  \n",
    "y: [51.816 (up), -51.689 (down)]  unit: mm\n",
    "\n",
    "so the scale relationship is 0.0398 mm/pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "import matplotlib.path as mpltPath\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageToXML(coodinate):\n",
    "    # transfer coodinate of carousel image to XML file coodinate\n",
    "    x, y = coodinate\n",
    "    xmlx = str(round(1035050*x/2600 - 518160))\n",
    "    xmly = str(round(518160 - 1035050*y/2600))\n",
    "    return xmlx, xmly\n",
    "    \n",
    "def XMLToImage(coodinate):\n",
    "    # transfer coodinate of XML file to carousel image coodinate\n",
    "    xmlx, xmly = coodinate\n",
    "    x = str(round((xmlx+518160)/1035050*2600))\n",
    "    y = str(round((518160-xmly)/1035050*2600))\n",
    "    return x, y\n",
    "\n",
    "def firstPointCoodinatExtractor(xmlName):\n",
    "    # extract the point you selected from the carousel image, as xml coodinate and return\n",
    "    xmlfile = ET.ElementTree(file=xmlName)\n",
    "    root = xmlfile.getroot()\n",
    "    coodinate = (int(root[0][-1][0].attrib['XAttrib']), int(root[0][-1][0].attrib['YAttrib']))\n",
    "    return coodinate\n",
    "\n",
    "def xmlFileWriter(xmlfileName, PointList, imgCoodinate):\n",
    "    # based on XML file with the point you selected, add all the point recognized from carousel image, then append to the end\n",
    "    # of that XML file\n",
    "    realX, realY = firstPointCoodinatExtractor(xmlfileName)\n",
    "    imgX, imgY = imgCoodinate # in mm unit\n",
    "    ErrorX = int(imgX) - int(realX)\n",
    "    ErrorY = int(imgY) - int(realY)\n",
    "    \n",
    "    xmlfile = ET.ElementTree(file=xmlfileName)\n",
    "    root = xmlfile.getroot()\n",
    "    for i in range(1, len(PointList)+1): # mind here, need change\n",
    "        a = copy.deepcopy(root[0][4])\n",
    "        a.attrib = {'PointName': root[0][4].attrib['PointName'] + '_' + str(i)}\n",
    "        tempX, tempY = imageToXML(PointList[i-1])\n",
    "        a[0].attrib['XAttrib'] = str(round(int(tempX) + ErrorX))\n",
    "        a[0].attrib['YAttrib'] = str(round(int(tempY) + ErrorY))\n",
    "        \n",
    "        root[0].append(a)\n",
    "    xmlfile.write('ALL_'+xmlfileName)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foundAllPoints(img, sampleType, position):\n",
    "    \"\"\"\n",
    "    param: \n",
    "    img, the input image read by imread;\n",
    "    sampleType, the type of sample, large ('LRG') or small ('SML') TMA.\n",
    "    position, the image region that want to be selected, ('UP', 'DOWN').\n",
    "    \"\"\"\n",
    "    pointsList = []\n",
    "    if position == 'UP':\n",
    "        tempList, coodinate = foundPoints(img, 827, 609, sampleType)\n",
    "    elif position == 'DOWN':\n",
    "        tempList, coodinate = foundPoints(img, 827, 1447, sampleType)        \n",
    "    \"\"\"\n",
    "    # for future development, for now it can only observe upper or lower slides region\n",
    "    elif position == 'ALL':\n",
    "        tempList, coodinate = foundPoints(img, 827, 609, sampleType)\n",
    "        pointsList += tempList\n",
    "        tempList, coodinate = foundPoints(img, 827, 1447, sampleType)\n",
    "        pointsList += tempList\n",
    "    \"\"\"\n",
    "    pointsList += tempList\n",
    "    return pointsList, coodinate\n",
    "\n",
    "def foundALLPoints(img, xModify, yModify, sampleType):    \n",
    "    imgPos = img[yModify:yModify+540, 827:2200]\n",
    "    gray = cv2.cvtColor(imgPos, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (9, 9),0) \n",
    "    (_, thresh) = cv2.threshold(blurred, 90, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    closed = cv2.erode(closed, None, iterations=4)\n",
    "    closed = cv2.dilate(closed, None, iterations=4)\n",
    "    \n",
    "    images, cnts, hierarchy = cv2.findContours(closed.copy(), cv2.CHAIN_APPROX_NONE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(\"length of cnts: \", len(cnts))\n",
    "    \n",
    "    spotList = []\n",
    "    for i in range(len(cnts)): \n",
    "        #x,y,w,h = cv2.boundingRect(cnts[i])\n",
    "        (x,y),radius = cv2.minEnclosingCircle(cnts[i])\n",
    "        center = (int(x)+827, int(y)+609)\n",
    "        radius = int(radius)\n",
    "        if sampleType == 'LRG':\n",
    "            if radius > 15 and radius < 30:\n",
    "                spotList.append(center)\n",
    "                cv2.circle(img, center, radius, (0,255,0), 2)\n",
    "            #if w > 20 and h > 20 and w < 60 and h < 60:\n",
    "                #spotList.append((x+xModify+w//2, y+yModify+h//2))\n",
    "                #cv2.rectangle(img,(x+xModify,y+yModify),(x+xModify+w,y+yModify+h),(0,255,0),2)\n",
    "        elif sampleType == 'SML':\n",
    "            if radius > 5 and radius < 15:\n",
    "                spotList.append(center)\n",
    "                cv2.circle(img, center, radius, (0,255,0), 2)\n",
    "            #if w > 10 and h > 10 and w < 30 and h < 30:\n",
    "                #spotList.append((x+xModify+w//2, y+yModify+h//2))\n",
    "                #cv2.rectangle(img,(x+xModify,y+yModify),(x+xModify+w,y+yModify+h),(0,255,0),2)\n",
    "    randomX, randomY = choice(spotList)\n",
    "    pt1 = (randomX+7, randomY+7)\n",
    "    pt2 = (randomX-7, randomY-7)\n",
    "    cv2.line(img, pt1, pt2, (255,0,0), 2)\n",
    "    pt1 = (randomX+7, randomY-7)\n",
    "    pt2 = (randomX-7, randomY+7)\n",
    "    cv2.line(img, pt1, pt2, (255,0,0), 2)\n",
    "                \n",
    "    a = \"contoursImage\"+str(len(cnts))+\".png\"\n",
    "    cv2.imwrite(a, img)\n",
    "    imgshow = Image.fromarray(img)\n",
    "    imgshow.show()\n",
    "    print(\"length of spots: \", len(spotList), '\\n')\n",
    "    coodinate = (randomX, randomY)\n",
    "    return spotList, coodinate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### step1: read the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"TMA_test2.jpg\")\n",
    "img = cv2.imread(\"081318_Ionpath_TMA_Tonsil.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### step2: process the image and generate all spots\n",
    "func foundAllPoints(img, sampleType, position)   \n",
    "Parameters:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;    Image: carousel image that read in last step  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;    TMA_type: choose from 'LRG' and 'SML', 'LRG' for 1.5 mm size TMA, 'SML' for 0.6 mm size TMA  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;    Postion: 'UP' indicate to process the upper channel of sample holder, 'DOWN' is the lower one.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of cnts:  64\n",
      "please select the center of red-colored cross on miniMIBI, and input the x,y for next function.\n",
      "length of spots:  41 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "spotslist, coodinate = foundAllPoints(img, 'LRG', 'UP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### user step\n",
    "Check the cross labeled region on popped-up carousel image, use SED to adjust your position, then do all setup for the spots (depth/dwelling time, etc.), save the XML file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### step3: process the image and generate all spots\n",
    "foundAllPoints(xmlfileName, PointList, imgCoodinate)   \n",
    "Parameters:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; xmlfilename: the name of XML file generated in user step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmlFileWriter('test.xml', spotslist, imageToXML(coodinate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiff_py=3.6",
   "language": "python",
   "name": "python3tiff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
